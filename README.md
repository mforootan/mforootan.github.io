# massiHUB
 
##### Coding Sandbox
[https://www.linkedin.com/in/massihforootan/](https://www.linkedin.com/in/massihforootan/)
 

------
## :: Improve College-Going and College-Readiness
###### Division of Research and Evaluation, TN Dept of Education
This [repository](https://github.com/mforootan/TN_DoE_College-Readiness) contains a Jupyter notebook file and data for an assessment project that aimed on identifying measures that can be used to evaluate highschool graduates' readiness for college studies.

Using PCA, feasible criteria was selected, on which basis the model schools was picked. 

With regards to data quality, however, there were both missing data and duplicated records in the dataset. The strategy to handle the data was discussed and implememnted. Future topics for studies (breaking the data within sub regions) were proposed.

------
## :: Fatal and Serious Injury Crashes
###### Tennessee Integrated Traffic Analysis Network, TN Dept of Safety & Homeland Security
This SQL / Tableau-powered [dashboard](https://www.tn.gov/safety/stats/dashboards/fatalseriousinjurycrashes.html) contains near-to-live interactive information on fatal and serious injury crashes on Tennessee roadways for the current and previous years.
This dashboard was presented in 2019 LifeSavers Conference ([Link](https://lifesaversconference.org/wp-content/uploads/2019/03/Forootan-ESP-06-a.pdf))

------
## :: Identify Reward Performance and Reward Progress Schools
###### Division of Strategy and Data, TN Dept of Education
This [repository](https://github.com/mforootan/Reward_Performance_Schools) contains R scripting files and data for an evaluation project that aimed on identifying schools with outstanding performance.

------
## :: Tennessee Traffic Fatality
###### Tennessee Integrated Traffic Analysis Network, TN Dept of Safety & Homeland Security
These two dashboards present a comparative [year-to-date](https://www.tn.gov/safety/stats/dashboards/trafficfatality.html) and [historical](https://www.tn.gov/safety/stats/dashboards/fatalityhistory.html) statistics on road fatality in the state, divided into individual vehicle-related and driver/passenger-related components.

------
## :: Land Use change in Tennessee
###### Nashville Software School
The objective of the project was to explore the pattern and hypothetical reasons for the changes in land use in Tennessee.
It consisted of two sub-projects:
- [Phase I](https://github.com/mforootan/NSS_MidStone_TN_Land_Use) (R & Shiny App): Visualizing the land use changes with an interactive dashboard.
- [Phase II](https://github.com/mforootan/NSS_Capstone_TN_land_use) (Python & SciKit): Identifying the measures that contribute to the land use changes using dimension reduction. A PowerPoint slideshow is included in this section that reviews the methodology and results.

The visuals indicated various patterns in correlation between land availability and value across counties. Analyses suggested the main criteria affecting land value are distance from major cities and the profitability of agriculture.

------
## :: Logistic Regression
###### Nashville Software School
This Jupyter [notebook](https://github.com/mforootan/NSS_Stat_LogReg) was created to demonstrate the concept of logistic regression, and how to implement one in Python.

------ 
##### ~ / M y _ L i f e / i n _ Z e r o e s _ a n d _ O n e $

###### I stepped into the programming world in my teens with a [CASIO FX-702P](https://www.google.com/search?q=casio+fx+702p) calculator. With a collection of built-in math functions and a BASIC programming language environment, it was a suitable tool for those who were interested in automating simple to semi-complex math problems. When home computers became popular (for dual use of gaming and programming), my pick was a [ZX-Spectrum +2](https://www.google.com/search?q=zx+spectrum+%2B2), pretty much for the same trend of programming interests. 

###### After PCs became popular during my undergrad, I started QBASIC and shortly afterward, [QuickBASIC](https://www.google.com/search?q=quickbasic). With genetics and statistics dominating my routine studies, digging into statistical programming became my top interest ([sample scripts](https://github.com/mforootan/QuickBASIC)). The big leap was starting to code for experimental designs and ANOVA, but before making significant progress, I learned about [MSTAT-C](https://www.google.com/search?q=mstatc), which terminated the rest of my coding plans.

###### Meanwhile, Windows 3.x had already entered the market, and it was evident that the MS-DOS-based programming era is almost over. It didnâ€™t take me long to find that Microsoft has released [Visual Basic](https://www.google.com/search?q=visual+basic+3), so I grabbed it and started migrating my old QB codes to the new platform to get my feet wet. When Windows 9x generation emerged, I felt my programming skills have become obsolete, thus gradually abandoned programming and focused on mastering spreadsheets (started with Lotus 1-2-3 but quickly switched to [Excel](https://www.google.com/search?q=excel+4.0)) for data wrangling and exploration.

###### By starting postgraduate studies after a long gap, I was urged to use statistical tools again. The need for coding skills was raised again with Windows 98 at its glorious days and Windows 2000 and XP coming up, and statistical packages (Minitab, SPSS, and [SAS](https://support.sas.com/documentation/onlinedoc/91pdf/) have become more user-friendly than ever, and learning resources were pretty well populated and accessible. Yet I could hardly be happier when found out that Visual Basic has become the kernel of macro language in Microsoft Office, specifically Excel. The [VBA](https://www.google.com/search?q=vba) and SAS programs thus became my main tools for programming and statistical analysis for nearly 10 years ([sample ANOVA templates](https://github.com/mforootan/SAS_ODS)).

###### Moving to the United States, I initially joined the IT-agribusiness sector, but after a while realized that my knowledge in statistics and coding is perilously out of date, and an update appears to be a must-do. This founded an incentive to join a data science boot camp and add [Python](https://www.python.org/) and [R](https://www.r-project.org/) languages to my set of skills; followed by [SQL](https://www.w3schools.com/sql/) and [Tableau](https://www.tableau.com/) for business intelligence purposes after rejoining the job market. With an ongoing data analysis career in a [Gen3](https://gen3.org/)-based data common, data querying with [API](https://www.google.com/search?q=api) and [GraphQL](https://graphql.org/) are my new areas of interest.

##### ~ / F u n _ F @ c t $
###### - My first email, registered in 1999, was an MS-DOS-based powered by [Pegasus Mail](http://www.pmail.com/overviews/ovw_pmail.htm). 
###### - I was among the first round of [blogger](http://massihforootan.blogspot.com/) users who were invited by Google to register for Gmail ([Story](https://www.theguardian.com/technology/blog/2004/apr/21/bloggerusersg)). Despite a wide range of usernames being available (including both my first and last name individually), I preferred to coin the very fourteen-character username I already had with Yahoo since 1999 (registered a few days after the Pegasus one) as my online identity. 
###### - Since then, I have owned email addresses with .net, .com, .ac.uk, .ac.ir, .gov, .org, and .edu domains; in that order.
###### - I am an Inbox Zero.
